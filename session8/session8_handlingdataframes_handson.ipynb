{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Psychologists - Session 8\n",
    "\n",
    "## hands on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your current working directory, i.e. where your notebook is saved on your disk. Todays data{}.csv sheets need to be in the same directory as your jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Use a for loop to create one dataframe that contains all .csv files for your 10 participants. Use the **os** module instead of creating a new subject list (hint: your files all end with .csv and os.listdir() shows you all files in your pwd). Hint: You need to set ```decimal=\",\" ``` when you use ```pd.read_csv```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: only the .csv files should be included in the overall data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df=[]\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file, sep=\";\", decimal=\",\")\n",
    "        all_df.append(df)\n",
    "\n",
    "df = pd.concat(all_df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Check the dataframe for missing values. If there are any missing values, replace it with 0 inside your current dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AmbigCorrectSwitch_RT\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Insert four new columns, that contain\n",
    "\n",
    "- Switchcost_Error = Error_Switch - Error_Baseline\n",
    "- Switchcost_RT = MeanRT_Switch - MeanRT_Baseline\n",
    "- Switchrate = switches / 20 \n",
    "- Ambig_RT = (AmbigCorrectStay_RT + AmbigCorrectSwitchRT) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Switchcost_error\"] = df[\"Error_Switch\"] - df[\"Error_Baseline\"]    #switchcost accuracy\n",
    "df[\"Switchcost_RT\"] = df[\"MeanRT_Switch\"] - df[\"MeanRT_Baseline\"]      #switchcost RT\n",
    "df[\"Switchrate\"] = df[\"switches\"]/20 \n",
    "df[\"Ambig_RT\"] = (df[\"AmbigCorrectStay_RT\"] + df[\"AmbigCorrectSwitch_RT\"])/2\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Sanity Check: Check whether Error_Baseline and Korrekt_Baseline adds up to 100% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitycheck = df[\"Error_Baseline\"] + df[\"Korrekt_Baseline\"] \n",
    "#sum(sanitycheck) == 10.0\n",
    "sanitycheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Check whether any participant has more than 30% errors in the baseline, switch or stay condition using ```df.loc```. Create a respective \"exclusion_{}.format(condition)\" list, that contains the participants and print it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_baseline = df.loc[df[\"Error_Baseline\"] > 0.3, \"subj_idx\"].tolist()\n",
    "exclusion_stay = df.loc[df[\"Error_Stay\"] > 0.3, \"subj_idx\"].tolist()\n",
    "exclusion_switch = df.loc[df[\"Error_Switch\"] > 0.3, \"subj_idx\"].tolist()\n",
    "\n",
    "print(exclusion_baseline)\n",
    "print(exclusion_stay)\n",
    "print(exclusion_switch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1) For educational purposes only: Combine all three exclusion lists to a single exclusion_overall list, that does only contain unique values (i.e. your participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_overall = list(set(exclusion_baseline+exclusion_stay+exclusion_switch))\n",
    "exclusion_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2) Now exclude cases in which \"Korrekt_Baseline\" is less than 95% and save the new data frame to a new variable \"df2\" **without** using ```df.loc```. Evaluate the new variable afterwards. Then, print a list of the subjects included in the new data frame \"df2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2= df[df[\"Korrekt_Baseline\"]<0.95]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df2[\"subj_idx\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Plot the RT for the baseline / stay / switch condition in one figure. Hint: Use sns.displot and 3 lines of code (see https://seaborn.pydata.org/generated/seaborn.distplot.html)\n",
    "\n",
    "- all conditions should have a different color \n",
    "- all conditions should have a label \n",
    "- plot only the distribution (i.e. set the hist parameter to False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[\"MeanRT_Baseline\"] , color=\"lightblue\", label=\"baseline\", hist=False)\n",
    "sns.distplot(df[\"MeanRT_Stay\"] , color=\"red\", label=\"stay\", hist=False)\n",
    "sns.distplot(df[\"MeanRT_Switch\"] , color=\"purple\", label=\"switch\", hist=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Backup the impression that RT increases with our task getting more cognitively demanding with the descriptive statistics. Mean results should be rounded to two decimals and fill in the respective values below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df[\"MeanRT_Baseline\"].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df[\"MeanRT_Stay\"].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df[\"MeanRT_Switch\"].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\"baseline\", \"stay\", \"switch\"]\n",
    "\n",
    "print(\"{}-RT: \".format(conditions[0]) + str(round(df[\"MeanRT_Baseline\"].mean(),2)))\n",
    "print(\"{}-RT: \".format(conditions[1]) + str(round(df[\"MeanRT_Stay\"].mean(),2)))\n",
    "print(\"{}-RT: \".format(conditions[2]) + str(round(df[\"MeanRT_Switch\"].mean(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) List comprehension\n",
    "\n",
    "- create a new random column that contains \"yes\" if a participant has more at least 95% accuracy in Baseline and Switch trials and \"no\" if not. Afterwards, print a list that contains only those subjects with a \"yes\" in your new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new\"] = [\"yes\" if a >= 0.95 and b >= 0.95 else \"no\" for (a,b) in zip(df[\"Korrekt_Baseline\"], df[\"Korrekt_Switch\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"new\"] == \"yes\"][\"subj_idx\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Correlate \"Switchcost_RT\" and \"Switchrate\" using the stats module. Please check whether both variables follow a normal distribution and choose either pearson or spearman correlation accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(df[\"Switchcost_RT\"])[1] < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(df[\"Switchrate\"])[1] < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(df[\"Switchcost_RT\"], df[\"Switchrate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 Now visualize the association of both variables using sns.jointplot (see https://seaborn.pydata.org/generated/seaborn.jointplot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(\"Switchcost_RT\", \"Switchrate\", data=df, kind=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Try to create a correlation matrix for your whole dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Create a new data frame \"wide\" consisting of the columns defined below. Then, set the index of \"wide\" to the subject index. Afterwards, use the `.stack()` method to create a new series called \"long\". Then, turn the series to a data frame. Finally, reset the index to numbers as before and rename the columns in a sensible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"MeanRT_Baseline\", \"MeanRT_Stay\", \"MeanRT_Switch\", \"subj_idx\"]\n",
    "\n",
    "wide = df[col]\n",
    "\n",
    "\n",
    "wide = wide.set_index(\"subj_idx\")\n",
    "long = wide.stack().to_frame()\n",
    "long = long.reset_index()\n",
    "long = long.rename(columns= {\"level_1\":\"condition\",0:\"RT\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Now our data is in the right format to easily plot multiple conditions (e.g., from a repeated measurement design) in one figure, i.e. next to each other. Try to use ```sns.violinplot```to plot all conditions and RTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"condition\", y=\"RT\", data=long)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
